[![python3.7.3](https://img.shields.io/badge/python-3.7.3-orange)](https://spacy.io)
[![spaCy](https://img.shields.io/badge/-spaCy-blue)](https://spacy.io)
[![gensim](https://img.shields.io/badge/gensim-Word2Vec-blue)](https://radimrehurek.com/gensim/)
[![nltk](https://img.shields.io/badge/-nltk-orange)](https://www.nltk.org)
[![vaderSentiment](https://img.shields.io/badge/-vaderSentiment-24292E)](https://github.com/cjhutto/vaderSentiment)
[![flask](https://img.shields.io/badge/-flask-363B3D)](https://palletsprojects.com/p/flask/)

# Opin - Amazon reviews filtering by Topics & Sentiment

This is an attempt at replicating the amazon reviews key-word filtering buttons, using sentiment analysis and topic modeling techniques with word embeddings.

#### This is a demo project and not a fulling functioning package.

<INSERT EXAMPLE AMAZON REVIEW BUTTONS>
![Example Amazon review buttons](https://github.com/andrewm-bose/Opin-ReviewsAnalysis/blob/master/flaskapp/imgs/Bose_Home_Speaker_500_Black_1.jpg)

## The Goal

## To try it out, you can run either the jupyter notebook or the ipython file for the following steps. The notebooks have extra EDA with some very interesting insights:
> preprocess.ipynb/py - cleans and tokenizes amazon electronics reviews dataset - 3.2M reviews, 62k products
> vectorize.ipynb/py - uses gensim word2vec to create word embeddings from preprocessed reviews
> main_single_run.ipynb/py - main program, performs topic modelling and sentiment analysis on a random product from the data set. Output ~15 topics with the customers' sentiment counts for the key words in that cluster.
> flaskapp/opin_app.py - runs a basic demo website to demonstrate the functionality of the model.

## EDA/insights

## Methodology
An initial dataset of 3.2M Amazon Electronics category customer reviews is tokenized using nltk and gensim: https://s3.amazonaws.com/amazon-reviews-pds/readme.html
>tokenizing is done with gensim.simple_preprocess, with all words lemmatized, removing stopwords, and finally using gensim Phrases to generate bigrams and trigrams.

From there, word embeddings were generated by training gensim Word2Vec on the full corpus of tokenized reviews.

From there, any random product can be extracted from the corpus, and the following techniques are applied:
>-Break the reviews into sentences using spacy, storing as a pandas DataFrame.
>-Use vader Sentiment to get the sentiment of each sentence, and use the compound score with a weighted average of the star rating to estimate the sentiment of the sentence.
>-For each token in the corpus of reviews for the one product, aggregate the positive and negative sentiment for all sentences containing that token.
>-Get the most popular keywords (tokens).
>-Using those keywords as topic (cluster) seeds, use Word2Vec to get the 6 most similar words in the corpus for that word.
>-Get the total sentiment counts for each word in each topic.
>-Take the top 15 topics based on a custom selection criteria of importance.

At the end of all that, you have your filter buttons, now filtering not but just a keyword but by topics.

## Other methods
Other methods were considered, including LDA and Kmeans cluster of words into topics, but this model ended up being simpler, faster, and more consistent.

## Future improvements:



## This readme is also still under construction. Everything will be more thoroughly explained in the coming weeks.

### Thanks for visiting!
